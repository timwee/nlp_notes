Word embeddings
-----------------






####################################################################################
Convolutions
####################################################################################

1. Add start and end word/character paddings
2. Use different filter sizes, each filter size will have multiple copies. (somewhat similar to ngram backoff models)
3. pool "over-time"


Debugging
------------
1. visualize 100 substrings with the highest filter response


References
------------
1. Kim 2014
2. Collobert 2011
3. Google Limit Lang model 2016



####################################################################################









####################################################################################















####################################################################################






####################################################################################







####################################################################################